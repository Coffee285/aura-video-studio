<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
      <title>Provider System Overview | Aura Video Studio </title>
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      <meta name="title" content="Provider System Overview | Aura Video Studio ">
      
      
      <link rel="icon" href="../../favicon.ico">
      <link rel="stylesheet" href="../../public/docfx.min.css">
      <link rel="stylesheet" href="../../public/main.css">
      <meta name="docfx:navrel" content="../../toc.html">
      <meta name="docfx:tocrel" content="../../toc.html">
      
      <meta name="docfx:rel" content="../../">
      
      
      <meta name="docfx:docurl" content="https://github.com/Coffee285/aura-video-studio/blob/main/docs/providers/README.md/#L1">
      <meta name="loc:inThisArticle" content="In this article">
      <meta name="loc:searchResultsCount" content="{count} results for &quot;{query}&quot;">
      <meta name="loc:searchNoResults" content="No results for &quot;{query}&quot;">
      <meta name="loc:tocFilter" content="Filter by title">
      <meta name="loc:nextArticle" content="Next">
      <meta name="loc:prevArticle" content="Previous">
      <meta name="loc:themeLight" content="Light">
      <meta name="loc:themeDark" content="Dark">
      <meta name="loc:themeAuto" content="Auto">
      <meta name="loc:changeTheme" content="Change theme">
      <meta name="loc:copy" content="Copy">
      <meta name="loc:downloadPdf" content="Download PDF">

      <script type="module" src="./../../public/docfx.min.js"></script>

      <script>
        const theme = localStorage.getItem('theme') || 'auto'
        document.documentElement.setAttribute('data-bs-theme', theme === 'auto' ? (window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light') : theme)
      </script>

  </head>

  <body class="tex2jax_ignore" data-layout="" data-yaml-mime="">
    <header class="bg-body border-bottom">
      <nav id="autocollapse" class="navbar navbar-expand-md" role="navigation">
        <div class="container-xxl flex-nowrap">
          <a class="navbar-brand" href="../../index.html">
            <img id="logo" class="svg" src="../../logo.svg" alt="Aura Video Studio">
            Aura Video Studio
          </a>
          <button class="btn btn-lg d-md-none border-0" type="button" data-bs-toggle="collapse" data-bs-target="#navpanel" aria-controls="navpanel" aria-expanded="false" aria-label="Toggle navigation">
            <i class="bi bi-three-dots"></i>
          </button>
          <div class="collapse navbar-collapse" id="navpanel">
            <div id="navbar">
              <form class="search" role="search" id="search">
                <i class="bi bi-search"></i>
                <input class="form-control" id="search-query" type="search" disabled placeholder="Search" autocomplete="off" aria-label="Search">
              </form>
            </div>
          </div>
        </div>
      </nav>
    </header>

    <main class="container-xxl">

      <div class="content">
        <div class="actionbar">

          <nav id="breadcrumb"></nav>
        </div>

        <article data-uid="">
<h1 id="provider-system-overview">Provider System Overview</h1>

<p>Aura Video Studio uses a modular provider system for AI services, allowing you to choose between cloud-based premium services, free alternatives, and local/offline options.</p>
<h2 id="provider-categories">Provider Categories</h2>
<h3 id="llm-providers-script-generation">LLM Providers (Script Generation)</h3>
<p>Generate video scripts from creative briefs.</p>
<table>
<thead>
<tr>
<th>Provider</th>
<th>Type</th>
<th>Cost</th>
<th>Quality</th>
<th>Offline</th>
<th>Configuration</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>OpenAI</strong> (GPT-4, GPT-3.5)</td>
<td>Cloud</td>
<td>Paid</td>
<td>Excellent</td>
<td>No</td>
<td>API key required</td>
</tr>
<tr>
<td><strong>Anthropic</strong> (Claude)</td>
<td>Cloud</td>
<td>Paid</td>
<td>Excellent</td>
<td>No</td>
<td>API key required</td>
</tr>
<tr>
<td><strong>Google Gemini</strong></td>
<td>Cloud</td>
<td>Free tier</td>
<td>Good</td>
<td>No</td>
<td>API key required</td>
</tr>
<tr>
<td><strong>Ollama</strong></td>
<td>Local</td>
<td>Free</td>
<td>Good</td>
<td>Yes</td>
<td>Local installation</td>
</tr>
<tr>
<td><strong>RuleBased</strong></td>
<td>Local</td>
<td>Free</td>
<td>Basic</td>
<td>Yes</td>
<td>No config needed</td>
</tr>
</tbody>
</table>
<p><strong>Recommended</strong>: Start with OpenAI GPT-4 for best results, use RuleBased as fallback for offline mode.</p>
<p><strong>Documentation</strong>:</p>
<ul>
<li><a href="UNIFIED_LLM_ORCHESTRATOR_GUIDE.html">LLM Orchestrator Guide</a></li>
<li><a href="LLM_CACHE_GUIDE.html">LLM Caching</a></li>
<li><a href="LLM_LATENCY_MANAGEMENT.html">LLM Latency Management</a></li>
<li><a href="LLM_OUTPUT_VALIDATION_GUIDE.html">LLM Output Validation</a></li>
<li><a href="OLLAMA_MODEL_SELECTION.html">Ollama Model Selection</a></li>
<li><a href="WINDOWS_LLM_PROVIDER_TESTING_GUIDE.html">Windows Testing Guide</a></li>
</ul>
<h3 id="tts-providers-voice-synthesis">TTS Providers (Voice Synthesis)</h3>
<p>Convert script text to speech audio.</p>
<table>
<thead>
<tr>
<th>Provider</th>
<th>Type</th>
<th>Cost</th>
<th>Quality</th>
<th>Offline</th>
<th>Voice Cloning</th>
<th>Configuration</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>ElevenLabs</strong></td>
<td>Cloud</td>
<td>Paid</td>
<td>Excellent</td>
<td>No</td>
<td>Yes</td>
<td>API key required</td>
</tr>
<tr>
<td><strong>PlayHT</strong></td>
<td>Cloud</td>
<td>Paid</td>
<td>Excellent</td>
<td>Yes</td>
<td>API key required</td>
<td></td>
</tr>
<tr>
<td><strong>Windows SAPI</strong></td>
<td>Local</td>
<td>Free</td>
<td>Good</td>
<td>Yes</td>
<td>No</td>
<td>Windows only, built-in</td>
</tr>
<tr>
<td><strong>Piper</strong></td>
<td>Local</td>
<td>Free</td>
<td>Good</td>
<td>Yes</td>
<td>No</td>
<td>Download models</td>
</tr>
<tr>
<td><strong>Mimic3</strong></td>
<td>Local</td>
<td>Free</td>
<td>Basic</td>
<td>Yes</td>
<td>No</td>
<td>Local installation</td>
</tr>
</tbody>
</table>
<p><strong>Recommended</strong>: ElevenLabs for premium projects, Windows SAPI for quick testing and offline work.</p>
<p><strong>Documentation</strong>:</p>
<ul>
<li><a href="TTS_VALIDATION_INDEX.html">TTS Validation Index</a></li>
<li><a href="TTS_VALIDATION_QUICK_START.html">TTS Quick Start</a></li>
</ul>
<h3 id="image-providers-visual-generation">Image Providers (Visual Generation)</h3>
<p>Generate or select images for video scenes.</p>
<table>
<thead>
<tr>
<th>Provider</th>
<th>Type</th>
<th>Cost</th>
<th>Quality</th>
<th>Offline</th>
<th>Configuration</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Stable Diffusion WebUI</strong></td>
<td>Local</td>
<td>Free</td>
<td>Excellent</td>
<td>Yes</td>
<td>Local GPU installation</td>
</tr>
<tr>
<td><strong>Replicate</strong></td>
<td>Cloud</td>
<td>Paid</td>
<td>Excellent</td>
<td>No</td>
<td>API key required</td>
</tr>
<tr>
<td><strong>Stock Images</strong></td>
<td>Fallback</td>
<td>Free</td>
<td>Basic</td>
<td>Yes</td>
<td>Built-in placeholders</td>
</tr>
</tbody>
</table>
<p><strong>Recommended</strong>: Stable Diffusion for best quality (requires GPU), Stock Images as fallback.</p>
<h3 id="video-rendering-ffmpeg">Video Rendering (FFmpeg)</h3>
<p>Render final video from timeline composition.</p>
<table>
<thead>
<tr>
<th>Method</th>
<th>Hardware</th>
<th>Performance</th>
<th>Quality</th>
<th>Configuration</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>NVENC</strong></td>
<td>NVIDIA GPU</td>
<td>Fastest</td>
<td>Excellent</td>
<td>Auto-detected</td>
</tr>
<tr>
<td><strong>AMF</strong></td>
<td>AMD GPU</td>
<td>Fast</td>
<td>Excellent</td>
<td>Auto-detected</td>
</tr>
<tr>
<td><strong>QuickSync</strong></td>
<td>Intel GPU</td>
<td>Fast</td>
<td>Good</td>
<td>Auto-detected</td>
</tr>
<tr>
<td><strong>CPU (libx264)</strong></td>
<td>CPU only</td>
<td>Slow</td>
<td>Excellent</td>
<td>Fallback</td>
</tr>
</tbody>
</table>
<p><strong>Recommended</strong>: Hardware acceleration automatically detected and used when available.</p>
<h2 id="provider-profiles">Provider Profiles</h2>
<p>Aura Video Studio includes pre-configured profiles to balance cost, quality, and availability:</p>
<h3 id="1-free-only-profile">1. Free-Only Profile</h3>
<ul>
<li><strong>LLM</strong>: RuleBased (offline)</li>
<li><strong>TTS</strong>: Windows SAPI or Piper (offline)</li>
<li><strong>Images</strong>: Stock images (offline)</li>
<li><strong>Rendering</strong>: CPU or available GPU</li>
</ul>
<p><strong>Use case</strong>: No API keys required, completely offline, basic quality.</p>
<h3 id="2-balanced-mix-profile">2. Balanced Mix Profile</h3>
<ul>
<li><strong>LLM</strong>: OpenAI with RuleBased fallback</li>
<li><strong>TTS</strong>: ElevenLabs with Windows SAPI fallback</li>
<li><strong>Images</strong>: Stable Diffusion with stock fallback</li>
<li><strong>Rendering</strong>: Hardware acceleration with CPU fallback</li>
</ul>
<p><strong>Use case</strong>: Best balance of quality and cost with resilient fallbacks.</p>
<h3 id="3-pro-max-profile">3. Pro-Max Profile</h3>
<ul>
<li><strong>LLM</strong>: OpenAI GPT-4 (primary), Claude (fallback)</li>
<li><strong>TTS</strong>: ElevenLabs (premium voices)</li>
<li><strong>Images</strong>: Stable Diffusion or Replicate</li>
<li><strong>Rendering</strong>: Hardware acceleration</li>
</ul>
<p><strong>Use case</strong>: Professional projects, maximum quality, API keys required.</p>
<h2 id="configuration">Configuration</h2>
<h3 id="api-keys">API Keys</h3>
<p>Store provider API keys securely:</p>
<ol>
<li><strong>Via UI</strong>: Settings → Providers → Enter API key</li>
<li><strong>Via Environment Variables</strong>: Set in <code>.env.local</code> file</li>
</ol>
<p>API keys are encrypted at rest using platform-appropriate storage.</p>
<p><strong>Documentation</strong>: <a href="PROVIDER_API_KEY_MANAGEMENT.html">Provider API Key Management</a></p>
<h3 id="provider-selection">Provider Selection</h3>
<p>Configure which providers to use for each service:</p>
<ol>
<li><strong>Automatic</strong>: Choose a provider profile (Free-Only, Balanced, Pro-Max)</li>
<li><strong>Manual</strong>: Select specific providers in Settings → Providers</li>
</ol>
<p>The system will automatically fall back to available providers if the primary fails.</p>
<p><strong>Documentation</strong>: <a href="PROVIDER_STICKINESS_USAGE_EXAMPLES.html">Provider Stickiness Usage</a></p>
<h3 id="fallback-strategy">Fallback Strategy</h3>
<p>When a provider fails, the system:</p>
<ol>
<li>Logs the failure with reason</li>
<li>Attempts the next provider in the fallback chain</li>
<li>Continues until success or all providers exhausted</li>
<li>Returns error only if all providers fail</li>
</ol>
<p>This ensures resilience even with intermittent API failures.</p>
<h2 id="performance-considerations">Performance Considerations</h2>
<h3 id="llm-providers">LLM Providers</h3>
<ul>
<li><strong>Latency</strong>: OpenAI and Anthropic typically respond in 2-10 seconds</li>
<li><strong>Caching</strong>: Responses cached to avoid redundant API calls</li>
<li><strong>Rate Limits</strong>: Automatic retry with exponential backoff</li>
</ul>
<h3 id="tts-providers">TTS Providers</h3>
<ul>
<li><strong>Latency</strong>: Cloud TTS (2-5 seconds per scene), Local TTS (&lt;1 second per scene)</li>
<li><strong>Quality vs Speed</strong>: Premium cloud services offer best quality but higher latency</li>
<li><strong>Batch Processing</strong>: Multiple scenes can be processed in parallel</li>
</ul>
<h3 id="image-providers">Image Providers</h3>
<ul>
<li><strong>Generation Time</strong>: Stable Diffusion (5-30 seconds per image depending on GPU)</li>
<li><strong>GPU Requirements</strong>: CUDA-capable NVIDIA GPU recommended for Stable Diffusion</li>
<li><strong>Fallback</strong>: Stock images instant, suitable for testing</li>
</ul>
<h3 id="video-rendering">Video Rendering</h3>
<ul>
<li><strong>Hardware Acceleration</strong>: 5-10x faster than CPU encoding</li>
<li><strong>Multi-pass Encoding</strong>: Higher quality at cost of longer render time</li>
<li><strong>Resolution Impact</strong>: 4K takes significantly longer than 1080p</li>
</ul>
<h2 id="troubleshooting">Troubleshooting</h2>
<h3 id="provider-not-available">Provider Not Available</h3>
<ul>
<li><strong>Check API key</strong>: Verify key is valid and has credits/quota remaining</li>
<li><strong>Check network</strong>: Cloud providers require internet connectivity</li>
<li><strong>Check local services</strong>: Ensure Ollama, Stable Diffusion WebUI, etc. are running</li>
</ul>
<h3 id="quality-issues">Quality Issues</h3>
<ul>
<li><strong>LLM</strong>: Try GPT-4 instead of GPT-3.5 for better script quality</li>
<li><strong>TTS</strong>: Premium providers (ElevenLabs, PlayHT) offer better voice quality</li>
<li><strong>Images</strong>: Use Stable Diffusion with appropriate prompts and settings</li>
</ul>
<h3 id="performance-issues">Performance Issues</h3>
<ul>
<li><strong>Enable hardware acceleration</strong>: Check GPU is detected in Settings → System</li>
<li><strong>Reduce quality settings</strong>: Lower resolution, bitrate, or use faster models</li>
<li><strong>Use local providers</strong>: Avoid network latency with offline alternatives</li>
</ul>
<h2 id="next-steps">Next Steps</h2>
<ul>
<li><a href="UNIFIED_LLM_ORCHESTRATOR_GUIDE.html">LLM Orchestrator Guide</a> - Deep dive into LLM system</li>
<li><a href="TTS_VALIDATION_QUICK_START.html">TTS Quick Start</a> - Set up text-to-speech</li>
<li><a href="PROVIDER_API_KEY_MANAGEMENT.html">API Key Management</a> - Secure key storage</li>
<li><a href="../user-guide/USER_MANUAL.html">User Guide</a> - Complete user documentation</li>
</ul>
<hr>
<p>Last updated: 2025-11-18</p>

</article>

        <div class="contribution d-print-none">
          <a href="https://github.com/Coffee285/aura-video-studio/blob/main/docs/providers/README.md/#L1" class="edit-link">Edit this page</a>
        </div>

        <div class="next-article d-print-none border-top" id="nextArticle"></div>

      </div>

      <div class="affix">
        <nav id="affix"></nav>
      </div>
    </main>

    <div class="container-xxl search-results" id="search-results"></div>

    <footer class="border-top text-secondary">
      <div class="container-xxl">
        <div class="flex-fill">
          © 2025 Aura Video Studio. Documentation built with DocFX.
        </div>
      </div>
    </footer>
  </body>
</html>
