{
  "version": "1.0",
  "engines": [
    {
      "id": "ffmpeg",
      "name": "FFmpeg",
      "version": "6.0",
      "description": "Essential video and audio processing toolkit for all media operations",
      "sizeBytes": 83558400,
      "sha256": "",
      "archiveType": "zip",
      "urls": {
        "windows": "https://github.com/BtbN/FFmpeg-Builds/releases/download/latest/ffmpeg-n6.0-latest-win64-gpl-6.0.zip",
        "linux": "https://johnvansickle.com/ffmpeg/releases/ffmpeg-release-amd64-static.tar.xz"
      },
      "mirrors": {
        "windows": [
          "https://github.com/BtbN/FFmpeg-Builds/releases/download/autobuild-2024-01-01-12-55/ffmpeg-n6.0-latest-win64-gpl-6.0.zip"
        ],
        "linux": [
          "https://johnvansickle.com/ffmpeg/old-releases/ffmpeg-6.0-amd64-static.tar.xz"
        ]
      },
      "extractDir": "ffmpeg",
      "entrypoint": "ffmpeg.exe",
      "licenseUrl": "https://www.ffmpeg.org/legal.html",
      "vramTooltip": "CPU-based tool, no GPU required. Works on all systems.",
      "icon": "üé¨",
      "tags": ["video", "audio", "cpu", "essential"]
    },
    {
      "id": "ollama",
      "name": "Ollama",
      "version": "0.1.19",
      "description": "Local LLM engine for script generation and AI narration without cloud APIs",
      "sizeBytes": 524288000,
      "sha256": "",
      "archiveType": "zip",
      "urls": {
        "windows": "https://github.com/ollama/ollama/releases/download/v0.1.19/ollama-windows-amd64.zip",
        "linux": "https://github.com/ollama/ollama/releases/download/v0.1.19/ollama-linux-amd64.tar.gz"
      },
      "extractDir": "ollama",
      "entrypoint": "ollama.exe",
      "defaultPort": 11434,
      "healthCheck": {
        "url": "/api/tags",
        "timeoutSeconds": 30
      },
      "licenseUrl": "https://github.com/ollama/ollama/blob/main/LICENSE",
      "vramTooltip": "CPU-based, but benefits from GPU acceleration if available. Works on all systems.",
      "icon": "ü§ñ",
      "tags": ["llm", "ai", "script-generation", "cpu"]
    },
    {
      "id": "stable-diffusion-webui",
      "name": "Stable Diffusion WebUI",
      "version": "1.9.0",
      "description": "AUTOMATIC1111's Stable Diffusion WebUI for local image generation",
      "sizeBytes": 2500000000,
      "sha256": "",
      "archiveType": "git",
      "urls": {
        "windows": "https://github.com/AUTOMATIC1111/stable-diffusion-webui.git",
        "linux": "https://github.com/AUTOMATIC1111/stable-diffusion-webui.git"
      },
      "entrypoint": "webui-user.bat",
      "defaultPort": 7860,
      "argsTemplate": "--api --listen",
      "healthCheck": {
        "url": "/sdapi/v1/sd-models",
        "timeoutSeconds": 120
      },
      "licenseUrl": "https://github.com/AUTOMATIC1111/stable-diffusion-webui/blob/master/LICENSE.txt",
      "requiredVRAMGB": 6,
      "vramTooltip": "Minimum 6GB VRAM for SD 1.5, 12GB+ recommended for SDXL. NVIDIA GPU required.",
      "icon": "üé®",
      "tags": ["image-generation", "ai", "nvidia-only", "gpu-intensive"]
    },
    {
      "id": "comfyui",
      "name": "ComfyUI",
      "version": "latest",
      "description": "ComfyUI - A powerful and modular stable diffusion GUI with node-based workflow",
      "sizeBytes": 1500000000,
      "sha256": "",
      "archiveType": "git",
      "urls": {
        "windows": "https://github.com/comfyanonymous/ComfyUI.git",
        "linux": "https://github.com/comfyanonymous/ComfyUI.git"
      },
      "entrypoint": "main.py",
      "defaultPort": 8188,
      "argsTemplate": "--listen 0.0.0.0 --port 8188",
      "healthCheck": {
        "url": "/system_stats",
        "timeoutSeconds": 60
      },
      "licenseUrl": "https://github.com/comfyanonymous/ComfyUI/blob/master/LICENSE",
      "requiredVRAMGB": 6,
      "vramTooltip": "Minimum 6GB VRAM for basic workflows. More VRAM for complex node graphs. NVIDIA GPU required.",
      "icon": "üîó",
      "tags": ["image-generation", "ai", "node-based", "nvidia-only", "gpu-intensive"]
    },
    {
      "id": "piper",
      "name": "Piper TTS",
      "version": "1.2.0",
      "description": "Fast, local neural text-to-speech system with high-quality voices",
      "sizeBytes": 50000000,
      "sha256": "",
      "archiveType": "zip",
      "urls": {
        "windows": "https://github.com/rhasspy/piper/releases/download/v1.2.0/piper_windows_amd64.zip",
        "linux": "https://github.com/rhasspy/piper/releases/download/v1.2.0/piper_linux_x86_64.tar.gz"
      },
      "extractDir": "piper",
      "entrypoint": "piper.exe",
      "licenseUrl": "https://github.com/rhasspy/piper/blob/master/LICENSE.md",
      "vramTooltip": "CPU-based TTS, no GPU required. Very fast and lightweight.",
      "icon": "üéôÔ∏è",
      "tags": ["tts", "cpu", "fast", "offline"],
      "models": [
        {
          "id": "en_US-lessac-medium",
          "name": "English US (Lessac Medium)",
          "url": "https://huggingface.co/rhasspy/piper-voices/resolve/main/en/en_US/lessac/medium/en_US-lessac-medium.onnx",
          "sizeBytes": 63201308
        }
      ]
    },
    {
      "id": "mimic3",
      "name": "Mimic3 TTS",
      "version": "latest",
      "description": "Privacy-focused local text-to-speech by Mycroft AI with multiple voice options",
      "sizeBytes": 100000000,
      "sha256": "",
      "archiveType": "git",
      "urls": {
        "windows": "https://github.com/MycroftAI/mimic3.git",
        "linux": "https://github.com/MycroftAI/mimic3.git"
      },
      "entrypoint": "mimic3-server",
      "defaultPort": 59125,
      "healthCheck": {
        "url": "/api/voices",
        "timeoutSeconds": 30
      },
      "licenseUrl": "https://github.com/MycroftAI/mimic3/blob/master/LICENSE",
      "vramTooltip": "CPU-based TTS, no GPU required. Higher quality than Piper but slower.",
      "icon": "üó£Ô∏è",
      "tags": ["tts", "cpu", "quality", "offline"]
    }
  ]
}
